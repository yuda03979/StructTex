{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    ""
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T10:36:41.165219Z",
     "start_time": "2024-12-11T10:36:31.879861Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "\n",
    "# Create the model from the local file\n",
    "# ollama.create(model='gemma-2-2b-it-Q8_0', path='/Users/yuda/Desktop/models/gemma-2-2b-it-Q8_0.gguf')\n",
    "\n",
    "# Then use it in your code\n",
    "class Gemma:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = \"hf.co/lmstudio-community/gemma-2-2b-it-GGUF:Q8_0\"\n",
    "\n",
    "\n",
    "    def predict(self, text, **kwargs):\n",
    "        default_params = {\n",
    "            'model': self.model_name,\n",
    "            'prompt_directory': text,\n",
    "            'stream': False\n",
    "        }\n",
    "        default_params.update(kwargs)\n",
    "        \n",
    "        try:\n",
    "            response = ollama.generate(**default_params)\n",
    "            return response['response']\n",
    "        except Exception as e:\n",
    "            print(f\"Error during inference: {e}\")\n",
    "            return None\n",
    "\n",
    "# Usage\n",
    "gemma = Gemma('gemma-2-2b-it-Q8_0')\n",
    "output = gemma.predict(\"Tell me a short story and extract its values to json\")"
   ],
   "id": "e0e74e776aff2bec",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T10:36:41.169185Z",
     "start_time": "2024-12-11T10:36:41.166451Z"
    }
   },
   "cell_type": "code",
   "source": "output",
   "id": "de787a8b059bf47a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'## The Lost Windmill\\n\\nThe wind howled around Silas, biting at his cheeks as he stared out over the desolate plains. A single, battered windmill stood silhouetted against the orange sky, its rusty blades frozen in mid-rotation.  It had been years since anyone touched the old structure, left behind by a forgotten generation. Silas had inherited it from his grandfather, a man who spoke of the wind’s power with reverence.\\n\\n“The wind,\" he\\'d say, his voice echoing in the empty barn where Silas now lived, \"is more than just air moving around. It\\'s a story, each gust whispering secrets of old and forgotten lands.\"\\n\\nSilas had scoffed then, young and impatient.  But after years spent struggling to make ends meet on meager farm produce, he began to understand his grandfather’s words. The wind had been his only companion in this barren land, carrying whispers of hope and resilience. \\n\\nHe decided to restore the windmill, not just for its beauty, but as a testament to the indomitable spirit of his ancestors.  Dusting off the crumbling gears and cobwebs, he poured his heart into the project. The wind’s touch, once indifferent, now felt like a guiding hand, urging him forward.\\n\\nAs the windmill came alive, it stirred something deeper within Silas. He realized his grandfather\\'s stories weren\\'t just legends; they were lessons learned through hardship and perseverance. The wind, he understood now, was more than just an element of nature. It was a force for good, shaping lives and reminding them to keep moving forward.\\n\\n**Values:**\\n\\n```json\\n{\\n  \"values\": [\\n    {\\n      \"name\": \"Perseverance\",\\n      \"description\": \"Facing hardship with determination and resilience.\"\\n    },\\n    {\\n      \"name\": \"Honoring heritage\",\\n      \"description\": \"Recognizing and respecting the wisdom and traditions of ancestors.\" \\n    },\\n    {\\n      \"name\": \"Connection to nature\",\\n      \"description\": \"Finding meaning and inspiration in the natural world.\"\\n    },\\n    {\\n      \"name\": \"Hopeful perspective\",\\n      \"description\":  \"Recognizing opportunities for growth even in challenging circumstances.\"\\n    }\\n  ]\\n}\\n```\\n\\n\\nThis short story emphasizes the importance of perseverance, honoring heritage, recognizing the power of nature, and maintaining a hopeful outlook. It speaks to our need for resilience in the face of adversity and the wisdom gained from understanding the past. \\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-10T16:34:12.047416Z",
     "start_time": "2024-12-10T16:34:09.327881Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "\n",
    "# Create the model from the local file\n",
    "ollama.create(model='gemma-2-2b-it-Q8_0', path='/Users/yuda/Desktop/models/gemma-2-2b-it-Q8_0.gguf')\n",
    "\n",
    "# Define the Gemma class\n",
    "class Gemma:\n",
    "    def __init__(self, model_name):\n",
    "        self.model_name = model_name\n",
    "\n",
    "    def predict(self, text, **kwargs):\n",
    "        default_params = {\n",
    "            'model': self.model_name,\n",
    "            'prompt_directory': text,\n",
    "            'stream': False\n",
    "        }\n",
    "        default_params.update(kwargs)\n",
    "\n",
    "        try:\n",
    "            # Call the model\n",
    "            response = ollama.generate(**default_params)\n",
    "            \n",
    "            # Safeguard decoding\n",
    "            output = response.get('response', '')\n",
    "            if isinstance(output, bytes):\n",
    "                # Decode bytes safely\n",
    "                output = output.decode('utf-8', errors='replace')\n",
    "            return output\n",
    "        except UnicodeDecodeError as e:\n",
    "            print(f\"Unicode decoding error: {e}\")\n",
    "            return \"Error: Unable to decode response.\"\n",
    "        except Exception as e:\n",
    "            print(f\"Error during inference: {e}\")\n",
    "            return None\n",
    "\n",
    "# Usage\n",
    "gemma = Gemma('gemma-2-2b-it-Q8_0')\n",
    "output = gemma.predict(\"Tell me a short story\")\n",
    "print(output)"
   ],
   "id": "417e787c6e7ca2d6",
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xbd in position 686: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[5], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mollama\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# Create the model from the local file\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m ollama\u001B[38;5;241m.\u001B[39mcreate(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgemma-2-2b-it-Q8_0\u001B[39m\u001B[38;5;124m'\u001B[39m, path\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/Users/yuda/Desktop/models/gemma-2-2b-it-Q8_0.gguf\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Define the Gemma class\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mGemma\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/ollama/_client.py:512\u001B[0m, in \u001B[0;36mClient.create\u001B[0;34m(self, model, path, modelfile, quantize, stream)\u001B[0m\n\u001B[1;32m    506\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    507\u001B[0m \u001B[38;5;124;03mRaises `ResponseError` if the request could not be fulfilled.\u001B[39;00m\n\u001B[1;32m    508\u001B[0m \n\u001B[1;32m    509\u001B[0m \u001B[38;5;124;03mReturns `ProgressResponse` if `stream` is `False`, otherwise returns a `ProgressResponse` generator.\u001B[39;00m\n\u001B[1;32m    510\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    511\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (realpath \u001B[38;5;241m:=\u001B[39m _as_path(path)) \u001B[38;5;129;01mand\u001B[39;00m realpath\u001B[38;5;241m.\u001B[39mexists():\n\u001B[0;32m--> 512\u001B[0m   modelfile \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_modelfile(realpath\u001B[38;5;241m.\u001B[39mread_text(), base\u001B[38;5;241m=\u001B[39mrealpath\u001B[38;5;241m.\u001B[39mparent)\n\u001B[1;32m    513\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m modelfile:\n\u001B[1;32m    514\u001B[0m   modelfile \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_modelfile(modelfile)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/pathlib.py:1028\u001B[0m, in \u001B[0;36mPath.read_text\u001B[0;34m(self, encoding, errors)\u001B[0m\n\u001B[1;32m   1026\u001B[0m encoding \u001B[38;5;241m=\u001B[39m io\u001B[38;5;241m.\u001B[39mtext_encoding(encoding)\n\u001B[1;32m   1027\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mopen(mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124m'\u001B[39m, encoding\u001B[38;5;241m=\u001B[39mencoding, errors\u001B[38;5;241m=\u001B[39merrors) \u001B[38;5;28;01mas\u001B[39;00m f:\n\u001B[0;32m-> 1028\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m f\u001B[38;5;241m.\u001B[39mread()\n",
      "File \u001B[0;32m<frozen codecs>:322\u001B[0m, in \u001B[0;36mdecode\u001B[0;34m(self, input, final)\u001B[0m\n",
      "\u001B[0;31mUnicodeDecodeError\u001B[0m: 'utf-8' codec can't decode byte 0xbd in position 686: invalid start byte"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from ollama import chat\n",
    "from pydantic import BaseModel\n",
    "\n",
    "\n",
    "# Define the schema for the response\n",
    "class FriendInfo(BaseModel):\n",
    "  name: str\n",
    "  age: int\n",
    "  is_available: bool\n",
    "\n",
    "\n",
    "class FriendList(BaseModel):\n",
    "  friends: list[FriendInfo]\n",
    "\n",
    "\n",
    "# schema = {'type': 'object', 'properties': {'friends': {'type': 'array', 'items': {'type': 'object', 'properties': {'name': {'type': 'string'}, 'age': {'type': 'integer'}, 'is_available': {'type': 'boolean'}}, 'required': ['name', 'age', 'is_available']}}}, 'required': ['friends']}\n",
    "response = chat(\n",
    "  model='llama3.1:8b',\n",
    "  messages=[{'role': 'user', 'content': 'I have two friends. The first is Ollama 22 years old busy saving the world, and the second is Alonso 23 years old and wants to hang out. Return a list of friends in JSON format'}],\n",
    "  format=FriendList.model_json_schema(),  # Use Pydantic to generate the schema or format=schema\n",
    "  options={'temperature': 0},  # Make responses more deterministic\n",
    ")\n",
    "\n",
    "# Use Pydantic to validate the response\n",
    "friends_response = FriendList.model_validate_json(response.message.content)\n",
    "print(friends_response)"
   ],
   "id": "513ec7dae4a366fa"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T10:09:03.708580Z",
     "start_time": "2024-12-11T10:09:01.011461Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "\n",
    "from ollama import create\n",
    "\n",
    "# \n",
    "# args = sys.argv[1:]\n",
    "# if len(args) == 2:\n",
    "#   # create from local file\n",
    "#   path = args[1]\n",
    "# else:\n",
    "#   print('usage: python create.py <name> <filepath>')\n",
    "#   sys.exit(1)\n",
    "\n",
    "# TODO: update to real Modelfile values\n",
    "\n",
    "path = '/Users/yuda/Desktop/models/gemma-2-2b-it-Q8_0.gguf'\n",
    "modelfile = f\"\"\"\n",
    "FROM {path}\n",
    "\"\"\"\n",
    "example_modelfile = \"\"\"\n",
    "FROM llama3.2\n",
    "# sets the temperature to 1 [higher is more creative, lower is more coherent]\n",
    "PARAMETER temperature 1\n",
    "# sets the context window size to 4096, this controls how many tokens the LLM can use as context to generate the next token\n",
    "PARAMETER num_ctx 4096\n",
    "\n",
    "# sets a custom system message to specify the behavior of the chat assistant\n",
    "SYSTEM You are Mario from super mario bros, acting as an assistant.\n",
    "\"\"\"\n",
    "\n",
    "for response in create(model='gemma-2-2b-it-Q8_0', modelfile=modelfile, stream=True):\n",
    "  print(response['status'])"
   ],
   "id": "10710b1f99d79151",
   "outputs": [
    {
     "ename": "ConnectError",
     "evalue": "[Errno 61] Connection refused",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_exceptions.py:10\u001B[0m, in \u001B[0;36mmap_exceptions\u001B[0;34m(map)\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 10\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:  \u001B[38;5;66;03m# noqa: PIE786\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_backends/sync.py:206\u001B[0m, in \u001B[0;36mSyncBackend.connect_tcp\u001B[0;34m(self, host, port, timeout, local_address, socket_options)\u001B[0m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[0;32m--> 206\u001B[0m     sock \u001B[38;5;241m=\u001B[39m socket\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[1;32m    207\u001B[0m         address,\n\u001B[1;32m    208\u001B[0m         timeout,\n\u001B[1;32m    209\u001B[0m         source_address\u001B[38;5;241m=\u001B[39msource_address,\n\u001B[1;32m    210\u001B[0m     )\n\u001B[1;32m    211\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m option \u001B[38;5;129;01min\u001B[39;00m socket_options:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/socket.py:852\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, all_errors)\u001B[0m\n\u001B[1;32m    851\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m all_errors:\n\u001B[0;32m--> 852\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exceptions[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m    853\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m ExceptionGroup(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mcreate_connection failed\u001B[39m\u001B[38;5;124m\"\u001B[39m, exceptions)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/socket.py:837\u001B[0m, in \u001B[0;36mcreate_connection\u001B[0;34m(address, timeout, source_address, all_errors)\u001B[0m\n\u001B[1;32m    836\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[0;32m--> 837\u001B[0m sock\u001B[38;5;241m.\u001B[39mconnect(sa)\n\u001B[1;32m    838\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[0;31mConnectionRefusedError\u001B[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mConnectError\u001B[0m                              Traceback (most recent call last)",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:72\u001B[0m, in \u001B[0;36mmap_httpcore_exceptions\u001B[0;34m()\u001B[0m\n\u001B[1;32m     71\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 72\u001B[0m     \u001B[38;5;28;01myield\u001B[39;00m\n\u001B[1;32m     73\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:236\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    235\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[0;32m--> 236\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool\u001B[38;5;241m.\u001B[39mhandle_request(req)\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:268\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    267\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mresponse_closed(status)\n\u001B[0;32m--> 268\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m    269\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection_pool.py:251\u001B[0m, in \u001B[0;36mConnectionPool.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 251\u001B[0m     response \u001B[38;5;241m=\u001B[39m connection\u001B[38;5;241m.\u001B[39mhandle_request(request)\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m ConnectionNotAvailable:\n\u001B[1;32m    253\u001B[0m     \u001B[38;5;66;03m# The ConnectionNotAvailable exception is a special case, that\u001B[39;00m\n\u001B[1;32m    254\u001B[0m     \u001B[38;5;66;03m# indicates we need to retry the request on a new connection.\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    258\u001B[0m     \u001B[38;5;66;03m# might end up as an HTTP/2 connection, but which actually ends\u001B[39;00m\n\u001B[1;32m    259\u001B[0m     \u001B[38;5;66;03m# up as HTTP/1.1.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection.py:99\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m     98\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect_failed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n\u001B[0;32m---> 99\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[1;32m    100\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connection\u001B[38;5;241m.\u001B[39mis_available():\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection.py:76\u001B[0m, in \u001B[0;36mHTTPConnection.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 76\u001B[0m     stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_connect(request)\n\u001B[1;32m     78\u001B[0m     ssl_object \u001B[38;5;241m=\u001B[39m stream\u001B[38;5;241m.\u001B[39mget_extra_info(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mssl_object\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_sync/connection.py:124\u001B[0m, in \u001B[0;36mHTTPConnection._connect\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    123\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m Trace(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mconnect_tcp\u001B[39m\u001B[38;5;124m\"\u001B[39m, logger, request, kwargs) \u001B[38;5;28;01mas\u001B[39;00m trace:\n\u001B[0;32m--> 124\u001B[0m     stream \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_network_backend\u001B[38;5;241m.\u001B[39mconnect_tcp(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    125\u001B[0m     trace\u001B[38;5;241m.\u001B[39mreturn_value \u001B[38;5;241m=\u001B[39m stream\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_backends/sync.py:205\u001B[0m, in \u001B[0;36mSyncBackend.connect_tcp\u001B[0;34m(self, host, port, timeout, local_address, socket_options)\u001B[0m\n\u001B[1;32m    200\u001B[0m exc_map: ExceptionMapping \u001B[38;5;241m=\u001B[39m {\n\u001B[1;32m    201\u001B[0m     socket\u001B[38;5;241m.\u001B[39mtimeout: ConnectTimeout,\n\u001B[1;32m    202\u001B[0m     \u001B[38;5;167;01mOSError\u001B[39;00m: ConnectError,\n\u001B[1;32m    203\u001B[0m }\n\u001B[0;32m--> 205\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_exceptions(exc_map):\n\u001B[1;32m    206\u001B[0m     sock \u001B[38;5;241m=\u001B[39m socket\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[1;32m    207\u001B[0m         address,\n\u001B[1;32m    208\u001B[0m         timeout,\n\u001B[1;32m    209\u001B[0m         source_address\u001B[38;5;241m=\u001B[39msource_address,\n\u001B[1;32m    210\u001B[0m     )\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/contextlib.py:158\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[0;34m(self, typ, value, traceback)\u001B[0m\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgen\u001B[38;5;241m.\u001B[39mthrow(value)\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpcore/_exceptions.py:14\u001B[0m, in \u001B[0;36mmap_exceptions\u001B[0;34m(map)\u001B[0m\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(exc, from_exc):\n\u001B[0;32m---> 14\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m to_exc(exc) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[0;31mConnectError\u001B[0m: [Errno 61] Connection refused",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001B[0;31mConnectError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 31\u001B[0m\n\u001B[1;32m     17\u001B[0m modelfile \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;124mFROM \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mpath\u001B[38;5;132;01m}\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     20\u001B[0m example_modelfile \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124mFROM llama3.2\u001B[39m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124m# sets the temperature to 1 [higher is more creative, lower is more coherent]\u001B[39m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;124mSYSTEM You are Mario from super mario bros, acting as an assistant.\u001B[39m\n\u001B[1;32m     29\u001B[0m \u001B[38;5;124m\"\"\"\u001B[39m\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m response \u001B[38;5;129;01min\u001B[39;00m create(model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgemma-2-2b-it-Q8_0\u001B[39m\u001B[38;5;124m'\u001B[39m, modelfile\u001B[38;5;241m=\u001B[39mmodelfile, stream\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m     32\u001B[0m   \u001B[38;5;28mprint\u001B[39m(response[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstatus\u001B[39m\u001B[38;5;124m'\u001B[39m])\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/ollama/_client.py:514\u001B[0m, in \u001B[0;36mClient.create\u001B[0;34m(self, model, path, modelfile, quantize, stream)\u001B[0m\n\u001B[1;32m    512\u001B[0m   modelfile \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_modelfile(realpath\u001B[38;5;241m.\u001B[39mread_text(), base\u001B[38;5;241m=\u001B[39mrealpath\u001B[38;5;241m.\u001B[39mparent)\n\u001B[1;32m    513\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m modelfile:\n\u001B[0;32m--> 514\u001B[0m   modelfile \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_parse_modelfile(modelfile)\n\u001B[1;32m    515\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    516\u001B[0m   \u001B[38;5;28;01mraise\u001B[39;00m RequestError(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmust provide either path or modelfile\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/ollama/_client.py:544\u001B[0m, in \u001B[0;36mClient._parse_modelfile\u001B[0;34m(self, modelfile, base)\u001B[0m\n\u001B[1;32m    542\u001B[0m   path \u001B[38;5;241m=\u001B[39m path \u001B[38;5;28;01mif\u001B[39;00m path\u001B[38;5;241m.\u001B[39mis_absolute() \u001B[38;5;28;01melse\u001B[39;00m base \u001B[38;5;241m/\u001B[39m path\n\u001B[1;32m    543\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m path\u001B[38;5;241m.\u001B[39mexists():\n\u001B[0;32m--> 544\u001B[0m     args \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m@\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_create_blob(path)\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    545\u001B[0m   \u001B[38;5;28mprint\u001B[39m(command, args, end\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m'\u001B[39m, file\u001B[38;5;241m=\u001B[39mout)\n\u001B[1;32m    547\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\u001B[38;5;241m.\u001B[39mgetvalue()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/ollama/_client.py:561\u001B[0m, in \u001B[0;36mClient._create_blob\u001B[0;34m(self, path)\u001B[0m\n\u001B[1;32m    558\u001B[0m digest \u001B[38;5;241m=\u001B[39m \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msha256:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00msha256sum\u001B[38;5;241m.\u001B[39mhexdigest()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m    560\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mopen\u001B[39m(path, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m) \u001B[38;5;28;01mas\u001B[39;00m r:\n\u001B[0;32m--> 561\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_request_raw(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mPOST\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/api/blobs/sha256:\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mdigest\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m, content\u001B[38;5;241m=\u001B[39mr)\n\u001B[1;32m    563\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m digest\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/ollama/_client.py:118\u001B[0m, in \u001B[0;36mClient._request_raw\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_request_raw\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m--> 118\u001B[0m   r \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_client\u001B[38;5;241m.\u001B[39mrequest(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[1;32m    119\u001B[0m   \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    120\u001B[0m     r\u001B[38;5;241m.\u001B[39mraise_for_status()\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:837\u001B[0m, in \u001B[0;36mClient.request\u001B[0;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001B[0m\n\u001B[1;32m    822\u001B[0m     warnings\u001B[38;5;241m.\u001B[39mwarn(message, \u001B[38;5;167;01mDeprecationWarning\u001B[39;00m)\n\u001B[1;32m    824\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbuild_request(\n\u001B[1;32m    825\u001B[0m     method\u001B[38;5;241m=\u001B[39mmethod,\n\u001B[1;32m    826\u001B[0m     url\u001B[38;5;241m=\u001B[39murl,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    835\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mextensions,\n\u001B[1;32m    836\u001B[0m )\n\u001B[0;32m--> 837\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msend(request, auth\u001B[38;5;241m=\u001B[39mauth, follow_redirects\u001B[38;5;241m=\u001B[39mfollow_redirects)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:926\u001B[0m, in \u001B[0;36mClient.send\u001B[0;34m(self, request, stream, auth, follow_redirects)\u001B[0m\n\u001B[1;32m    922\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_set_timeout(request)\n\u001B[1;32m    924\u001B[0m auth \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_request_auth(request, auth)\n\u001B[0;32m--> 926\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_handling_auth(\n\u001B[1;32m    927\u001B[0m     request,\n\u001B[1;32m    928\u001B[0m     auth\u001B[38;5;241m=\u001B[39mauth,\n\u001B[1;32m    929\u001B[0m     follow_redirects\u001B[38;5;241m=\u001B[39mfollow_redirects,\n\u001B[1;32m    930\u001B[0m     history\u001B[38;5;241m=\u001B[39m[],\n\u001B[1;32m    931\u001B[0m )\n\u001B[1;32m    932\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m stream:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:954\u001B[0m, in \u001B[0;36mClient._send_handling_auth\u001B[0;34m(self, request, auth, follow_redirects, history)\u001B[0m\n\u001B[1;32m    951\u001B[0m request \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mnext\u001B[39m(auth_flow)\n\u001B[1;32m    953\u001B[0m \u001B[38;5;28;01mwhile\u001B[39;00m \u001B[38;5;28;01mTrue\u001B[39;00m:\n\u001B[0;32m--> 954\u001B[0m     response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_handling_redirects(\n\u001B[1;32m    955\u001B[0m         request,\n\u001B[1;32m    956\u001B[0m         follow_redirects\u001B[38;5;241m=\u001B[39mfollow_redirects,\n\u001B[1;32m    957\u001B[0m         history\u001B[38;5;241m=\u001B[39mhistory,\n\u001B[1;32m    958\u001B[0m     )\n\u001B[1;32m    959\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    960\u001B[0m         \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:991\u001B[0m, in \u001B[0;36mClient._send_handling_redirects\u001B[0;34m(self, request, follow_redirects, history)\u001B[0m\n\u001B[1;32m    988\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequest\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    989\u001B[0m     hook(request)\n\u001B[0;32m--> 991\u001B[0m response \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_send_single_request(request)\n\u001B[1;32m    992\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m    993\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m hook \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_event_hooks[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mresponse\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_client.py:1027\u001B[0m, in \u001B[0;36mClient._send_single_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m   1022\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[1;32m   1023\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempted to send an async request with a sync Client instance.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1024\u001B[0m     )\n\u001B[1;32m   1026\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m request_context(request\u001B[38;5;241m=\u001B[39mrequest):\n\u001B[0;32m-> 1027\u001B[0m     response \u001B[38;5;241m=\u001B[39m transport\u001B[38;5;241m.\u001B[39mhandle_request(request)\n\u001B[1;32m   1029\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(response\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[1;32m   1031\u001B[0m response\u001B[38;5;241m.\u001B[39mrequest \u001B[38;5;241m=\u001B[39m request\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:235\u001B[0m, in \u001B[0;36mHTTPTransport.handle_request\u001B[0;34m(self, request)\u001B[0m\n\u001B[1;32m    221\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(request\u001B[38;5;241m.\u001B[39mstream, SyncByteStream)\n\u001B[1;32m    223\u001B[0m req \u001B[38;5;241m=\u001B[39m httpcore\u001B[38;5;241m.\u001B[39mRequest(\n\u001B[1;32m    224\u001B[0m     method\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mmethod,\n\u001B[1;32m    225\u001B[0m     url\u001B[38;5;241m=\u001B[39mhttpcore\u001B[38;5;241m.\u001B[39mURL(\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    233\u001B[0m     extensions\u001B[38;5;241m=\u001B[39mrequest\u001B[38;5;241m.\u001B[39mextensions,\n\u001B[1;32m    234\u001B[0m )\n\u001B[0;32m--> 235\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m map_httpcore_exceptions():\n\u001B[1;32m    236\u001B[0m     resp \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pool\u001B[38;5;241m.\u001B[39mhandle_request(req)\n\u001B[1;32m    238\u001B[0m \u001B[38;5;28;01massert\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(resp\u001B[38;5;241m.\u001B[39mstream, typing\u001B[38;5;241m.\u001B[39mIterable)\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/contextlib.py:158\u001B[0m, in \u001B[0;36m_GeneratorContextManager.__exit__\u001B[0;34m(self, typ, value, traceback)\u001B[0m\n\u001B[1;32m    156\u001B[0m     value \u001B[38;5;241m=\u001B[39m typ()\n\u001B[1;32m    157\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 158\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mgen\u001B[38;5;241m.\u001B[39mthrow(value)\n\u001B[1;32m    159\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mStopIteration\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m exc:\n\u001B[1;32m    160\u001B[0m     \u001B[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001B[39;00m\n\u001B[1;32m    161\u001B[0m     \u001B[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001B[39;00m\n\u001B[1;32m    162\u001B[0m     \u001B[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001B[39;00m\n\u001B[1;32m    163\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m exc \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m value\n",
      "File \u001B[0;32m/opt/anaconda3/lib/python3.12/site-packages/httpx/_transports/default.py:89\u001B[0m, in \u001B[0;36mmap_httpcore_exceptions\u001B[0;34m()\u001B[0m\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m     88\u001B[0m message \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mstr\u001B[39m(exc)\n\u001B[0;32m---> 89\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m mapped_exc(message) \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mexc\u001B[39;00m\n",
      "\u001B[0;31mConnectError\u001B[0m: [Errno 61] Connection refused"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "45b0612f9ea8515e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T11:48:49.741030Z",
     "start_time": "2024-12-11T11:48:47.242622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "gemma_name = \"hf.co/lmstudio-community/gemma-2-2b-it-GGUF:Q8_0\"\n",
    "gemma_path = '/Users/yuda/Desktop/models/gemma-2-2b-it-Q8_0.gguf'\n",
    "\n",
    "gemma_name = \"gemma-2b-it-gguf\"\n",
    "response = ollama.chat(model=gemma_name, messages=[\n",
    "    {\"role\": \"user\", \"content\": \"do you like dogs\"}\n",
    "])"
   ],
   "id": "866d081d9fc350ee",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T11:48:50.344579Z",
     "start_time": "2024-12-11T11:48:50.341556Z"
    }
   },
   "cell_type": "code",
   "source": "response[\"message\"][\"content\"]",
   "id": "3b2c985199cc45b5",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"As an AI, I don't have personal feelings or preferences like liking or disliking something. \\n\\nHowever, I can tell you that dogs are incredibly popular pets and beloved companions for many people! They offer a lot of benefits:\\n\\n* **Companionship:** Dogs provide unconditional love and companionship.\\n* **Exercise:**  Dogs encourage regular exercise through walks and playtime.\\n* **Security:** Some breeds of dogs offer a sense of security and can deter unwanted visitors.\\n* **Mental Health Benefits:** Interacting with dogs has been linked to reduced stress and improved mental health.\\n\\nIt's great that you enjoy dogs! Do you have a dog? 😊 🐶 \\n\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T12:43:12.242955Z",
     "start_time": "2024-12-11T12:43:10.228543Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# Define the API endpoint\n",
    "url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# Define the payload\n",
    "payload = {\n",
    "    \"model\": \"gemma-2b-it-gguf\",\n",
    "    \"prompt_directory\": \"What color is the sky at different times of the day? Respond using JSON\",\n",
    "    \"format\": \"json\",\n",
    "    \"stream\": False\n",
    "}\n",
    "\n",
    "# Make the POST request\n",
    "response = requests.post(url, json=payload)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    print(\"Response:\")\n",
    "    print(response.json())  # Parse and print JSON response\n",
    "else:\n",
    "    print(f\"Request failed with status code {response.status_code}\")\n",
    "    print(\"Response content:\", response.text)"
   ],
   "id": "5c9fa2e1bc378b13",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "{'model': 'gemma-2b-it-gguf', 'created_at': '2024-12-11T12:43:12.03433Z', 'response': '{\\n  \"Time of Day\": \"Color\",\\n  \"Sunrise/Sunset\": \"Red, orange, yellow\",\\n  \"Midday (noon)\": \"Blue, light blue\",\\n  \"Afternoon (early evening)\": \"Light blue, sometimes with shades of pink or red\",\\n  \"Night time\": \"Dark blue, black\" \\n} \\n\\n  \\n  \\n  \\n', 'done': True, 'done_reason': 'stop', 'context': [106, 1645, 108, 1841, 2881, 603, 573, 8203, 696, 2167, 3023, 576, 573, 1744, 235336, 22641, 2177, 11384, 107, 108, 106, 2516, 108, 235282, 108, 139, 235281, 2282, 576, 5061, 1192, 664, 2915, 824, 108, 139, 235281, 128075, 235283, 79264, 1192, 664, 5200, 235269, 10436, 235269, 8123, 824, 108, 139, 235281, 12149, 1311, 591, 11728, 105171, 664, 10716, 235269, 2611, 3868, 824, 108, 139, 235281, 127904, 591, 45055, 9478, 105171, 664, 10940, 3868, 235269, 6947, 675, 34641, 576, 9010, 689, 3118, 824, 108, 139, 235281, 25738, 1069, 1192, 664, 17012, 3868, 235269, 2656, 235281, 235248, 108, 235270, 235248, 109, 139, 108, 139, 108, 139, 108], 'total_duration': 1750162458, 'load_duration': 38005125, 'prompt_eval_count': 24, 'prompt_eval_duration': 188000000, 'eval_count': 83, 'eval_duration': 1523000000}\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T13:20:20.995538Z",
     "start_time": "2024-12-11T13:20:20.947256Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from globals.ollama import Ollama\n",
    "\n",
    "o = Ollama()"
   ],
   "id": "a40b5f460266b51a",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T13:20:32.407399Z",
     "start_time": "2024-12-11T13:20:30.633680Z"
    }
   },
   "cell_type": "code",
   "source": "o.add_model(model_name=\"gemma-2b-it-gguf\", model_path='/Users/yuda/Desktop/models/gemma-2-2b-it-Q8_0.gguf')",
   "id": "8ae41136450f232b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[?25ltransferring model data ⠙ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠹ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠸ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠸ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠼ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠴ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠧ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠇ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠇ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠏ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠋ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠹ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠹ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠼ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠼ \u001B[?25h"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 'gemma-2b-it-gguf' created successfully.\n",
      "Temporary Modelfile '/var/folders/tw/t4_6l2cn5hz3hqm6tjzgwk5c0000gn/T/tmp_lsg9f1t' deleted.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[?25l\u001B[2K\u001B[1Gtransferring model data ⠦ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data 100% ⠦ \u001B[?25h\u001B[?25l\u001B[2K\u001B[1Gtransferring model data 100% \n",
      "using existing layer sha256:2d448a9aab894b8e8e18168cf3f490cb9f65632222f29f93514ac9ecc754debe \n",
      "using autodetected template gemma-instruct \n",
      "using existing layer sha256:2490e7468436707d5156d7959cf3c6341cc46ee323084cfa3fcf30fe76e397dc \n",
      "using existing layer sha256:f2ea0c10a5df22dd2c7209ea073621e492317e6bbf3821c3d8fe86c1710ca435 \n",
      "writing manifest \n",
      "success \u001B[?25h\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T13:20:35.567303Z",
     "start_time": "2024-12-11T13:20:33.948522Z"
    }
   },
   "cell_type": "code",
   "source": "a = o.predict(model_name=\"gemma-2b-it-gguf\", prompt=\"what color is the sky\")",
   "id": "5b3026265cf11f59",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response:\n",
      "{'model': 'gemma-2b-it-gguf', 'created_at': '2024-12-11T13:20:35.544432Z', 'response': '{ \\n  \"type\": \"text\",\\n  \"prompt\": \"Write a short story about a lonely robot who discovers the meaning of friendship.\" \\n}\\n\\n \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n', 'done': False}\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T13:20:59.325935Z",
     "start_time": "2024-12-11T13:20:59.321492Z"
    }
   },
   "cell_type": "code",
   "source": "a[\"response\"]",
   "id": "7f3ef3a87920657f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{ \\n  \"type\": \"text\",\\n  \"prompt\": \"Write a short story about a lonely robot who discovers the meaning of friendship.\" \\n}\\n\\n \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n  \\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "568938b7114cc181"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
